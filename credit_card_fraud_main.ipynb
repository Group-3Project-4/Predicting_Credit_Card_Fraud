{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from sqlalchemy import create_engine, MetaData, select\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from config import database_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Path\n",
    "\n",
    "learning_data = Path('../Data_2/creditcard_2023.csv')\n",
    "\n",
    "learning_df = pd.read_csv(learning_data, encoding='utf-8')\n",
    "\n",
    "learning_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "\n",
    "learning_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row count\n",
    "\n",
    "num_rows = len(learning_df)\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "\n",
    "# Convert non-float values to NaN\n",
    "learning_df = learning_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows containing NaN values\n",
    "cleaned_learning_df = learning_df.dropna()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(cleaned_learning_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row count\n",
    "\n",
    "num_rows = len(cleaned_learning_df)\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned data\n",
    "\n",
    "cleaned_learning_df.to_csv('../Data_2/cleaned_creditcard_2023.csv', encoding=\"utf-8\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating SQL database\n",
    "\n",
    "connection_params = database_params\n",
    "\n",
    "connection = psycopg2.connect(**connection_params)\n",
    "\n",
    "connection.autocommit = True\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Create the database\n",
    "cursor.execute(\"CREATE DATABASE creditcardtransactions\")\n",
    "\n",
    "# Commit the changes and close the connection to the default database\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table\n",
    "\n",
    "connection_params = { **database_params,\n",
    "                     'dbname' : 'creditcardtransactions'}\n",
    "\n",
    "connection = psycopg2.connect(**connection_params)\n",
    "\n",
    "connection.autocommit = True\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Create the table\n",
    "create_credit_card_table = \"\"\"\n",
    "DROP TABLE IF EXISTS CreditCardTransactions;\n",
    "CREATE TABLE CreditCardTransactions (\n",
    "    id INT,\n",
    "    V1 NUMERIC,\n",
    "\tV2 NUMERIC,\n",
    "\tV3 NUMERIC,\n",
    "\tV4 NUMERIC,\n",
    "\tV5 NUMERIC,\n",
    "\tV6 NUMERIC,\n",
    "\tV7 NUMERIC,\n",
    "\tV8 NUMERIC,\n",
    "\tV9 NUMERIC,\n",
    "\tV10 NUMERIC,\n",
    "\tV11 NUMERIC,\n",
    "\tV12 NUMERIC,\n",
    "\tV13 NUMERIC,\n",
    "\tV14 NUMERIC,\n",
    "\tV15 NUMERIC,\n",
    "\tV16 NUMERIC,\n",
    "\tV17 NUMERIC,\n",
    "\tV18 NUMERIC,\n",
    "\tV19 NUMERIC,\n",
    "\tV20 NUMERIC,\n",
    "\tV21 NUMERIC,\n",
    "\tV22 NUMERIC,\n",
    "\tV23 NUMERIC,\n",
    "\tV24 NUMERIC,\n",
    "\tV25 NUMERIC,\n",
    "\tV26 NUMERIC,\n",
    "\tV27 NUMERIC,\n",
    "\tV28 NUMERIC,\n",
    "\tAmount Numeric,\n",
    "\tclass INT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_credit_card_table)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the target variable (class)\n",
    "sns.countplot(x = 'class', data = cleaned_learning_df)\n",
    "plt.title('Prediction of Fraudulant Transactions')\n",
    "plt.show()\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = cleaned_learning_df.drop('class', axis = 1)\n",
    "y = cleaned_learning_df['class']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Build a logistic regression model\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Scatter plot for different perspective\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Scatter plot of the two principal components\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette='coolwarm', alpha=0.6)\n",
    "plt.title('Scatter plot of Credit Card Transactions (2D PCA)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(title='Class', loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1 - Report Explained\n",
    "Precision: Precision measures the accuracy of the positive predictions made by the model. For class 0, it indicates the proportion of correctly predicted instances among all instances predicted as class 0. Similarly, for class 1, it represents the proportion of correctly predicted instances among all instances predicted as class 1. In this report, both classes have a precision of 1.00, indicating that all positive predictions made by the model were correct.\n",
    "\n",
    "Recall: Recall, also known as sensitivity, measures the ability of the model to capture all positive instances of the class. For class 0, it represents the proportion of correctly predicted instances of class 0 among all actual instances of class 0. Similarly, for class 1, it indicates the proportion of correctly predicted instances of class 1 among all actual instances of class 1. Like precision, both classes have a recall of 1.00, indicating that the model correctly identified all instances of both classes.\n",
    "\n",
    "F1-score: The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall and is particularly useful when the classes are imbalanced. Like precision and recall, the F1-score ranges from 0 to 1, with higher values indicating better performance. In this report, both classes have an F1-score of 1.00, indicating perfect balance between precision and recall.\n",
    "\n",
    "Support: Support represents the number of actual occurrences of each class in the dataset. For class 0, there are 56,734 instances, and for class 1, there are 56,992 instances.\n",
    "\n",
    "Accuracy: Accuracy measures the overall correctness of the model's predictions across all classes. In this case, the model achieved an accuracy of 1.00, indicating that all predictions, both positive and negative, were correct.\n",
    "\n",
    "Additionally, the confusion matrix provided at the end of the report summarizes the model's predictions. In this case, the model made 56,669 correct predictions for class 0 and 56,870 correct predictions for class 1. It incorrectly classified 65 instances of class 0 as class 1 and 122 instances of class 1 as class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes in the training set before random oversampling\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating Features and Target Variable\n",
    "X = cleaned_learning_df.drop('class', axis = 1)\n",
    "y = cleaned_learning_df['class']\n",
    "\n",
    "# Splitting Data into Training and Test Sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler=StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Building and Training the Decision Tree Classifier\n",
    "dt=DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Predictions \n",
    "y_test_pred=dt.predict(X_test_scaled)\n",
    "y_train_pred=dt.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_test = dt.predict(X_test_scaled)\n",
    "\n",
    "# Predict on the training set (optional, for comparison)\n",
    "y_pred_train = dt.predict(X_train_scaled)\n",
    "\n",
    "# Calculate accuracy for test set\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Calculate accuracy for training set (optional, for comparison)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"Accuracy on Test Set:\", accuracy_test)\n",
    "print(\"Accuracy on Training Set:\", accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(dt, 'decision_tree_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the distribution of the target variable (class)\n",
    "sns.countplot(x='class', data=cleaned_learning_df)\n",
    "plt.title('Logistic Regression Prediction of Fraudulent Transactions')\n",
    "plt.show()\n",
    "\n",
    "# Split the data - features (X) and target variable (y)\n",
    "X = cleaned_learning_df.drop('class', axis=1)\n",
    "y = cleaned_learning_df['class']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = model.score(X_test, y_test)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Create a Scatter plot for different perspective\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Scatter plot of the two principal components\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette='coolwarm', alpha=0.6)\n",
    "plt.title('Logistic Regression Scatter plot of Credit Card Transactions (2D PCA)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(title='Class', loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Re-evaluate the model and print the accuracy and classification report\n",
    "print(f\"Logistic Regression Accuracy: {accuracy}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report\n",
    "Precision: Precision measures the accuracy of the positive predictions made by the model. For class 0, it indicates the proportion of correctly predicted instances among all instances predicted as class 0. Similarly, for class 1, it represents the proportion of correctly predicted instances among all instances predicted as class 1. In this report, both classes have a precision of 1.00, indicating that all positive predictions made by the model were correct.\n",
    "\n",
    "Recall: Recall, also known as sensitivity, measures the ability of the model to capture all positive instances of the class. For class 0, it represents the proportion of correctly predicted instances of class 0 among all actual instances of class 0. Similarly, for class 1, it indicates the proportion of correctly predicted instances of class 1 among all actual instances of class 1. Like precision, both classes have a recall of 1.00, indicating that the model correctly identified all instances of both classes.\n",
    "\n",
    "F1-score: The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall and is particularly useful when the classes are imbalanced. Like precision and recall, the F1-score ranges from 0 to 1, with higher values indicating better performance. In this report, both classes have an F1-score of 1.00, indicating perfect balance between precision and recall.\n",
    "\n",
    "Support: Support represents the number of actual occurrences of each class in the dataset. For class 0, there are 56,734 instances, and for class 1, there are 56,992 instances.\n",
    "\n",
    "Accuracy: Accuracy measures the overall correctness of the model's predictions across all classes. In this case, the model achieved an accuracy of 1.00, indicating that all predictions, both positive and negative, were correct.\n",
    "\n",
    "Additionally, the confusion matrix provided at the end of the report summarizes the model's predictions. In this case, the model made 56,669 correct predictions for class 0 and 56,870 correct predictions for class 1. It incorrectly classified 65 instances of class 0 as class 1 and 122 instances of class 1 as class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the target variable (class)\n",
    "sns.countplot(x = 'class', data = cleaned_learning_df)\n",
    "plt.title('Prediction of Fraudulent Transactions')\n",
    "plt.show()\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = cleaned_learning_df.drop('class', axis=1)\n",
    "y = cleaned_learning_df['class']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialise lists to store optimisation results\n",
    "accuracy_list = []\n",
    "conf_matrix_list = []\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform model optimization\n",
    "for max_iter in [100, 500, 1000]:\n",
    "    \n",
    "    # Build a logistic regression model\n",
    "    model = LogisticRegression(max_iter=max_iter)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    accuracy_list.append(accuracy)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrix_list.append(conf_matrix)\n",
    "\n",
    "    print(f\"Max Iterations: {max_iter}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\\n\")\n",
    "\n",
    "# Display overall model performance\n",
    "best_max_iter = [100, 500, 1000][accuracy_list.index(max(accuracy_list))]\n",
    "print(f\"Best Max Iterations: {best_max_iter}\")\n",
    "print(\"Overall Model Performance:\")\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "print(f\"Overall Accuracy: {max(accuracy_list)}\")\n",
    "print(f\"Overall Confusion Matrix:\\n{conf_matrix_list[accuracy_list.index(max(accuracy_list))]}\")\n",
    "\n",
    "# Plot confusion matrix of the best performing model\n",
    "plt.figure()\n",
    "sns.heatmap(conf_matrix_list[accuracy_list.index(max(accuracy_list))], annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Best Performing Model)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the target variable (class)\n",
    "sns.countplot(x = 'class', data = cleaned_learning_df)\n",
    "plt.title('Prediction of Fraudulent Transactions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "X = cleaned_learning_df.drop('class', axis=1)\n",
    "y = cleaned_learning_df['class']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialise lists to store optimisation results\n",
    "accuracy_list = []\n",
    "conf_matrix_list = []\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform model optimization\n",
    "for max_iter in [100, 500, 1000]:\n",
    "    \n",
    "    # Build a logistic regression model\n",
    "    model = LogisticRegression(max_iter=max_iter)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    accuracy_list.append(accuracy)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrix_list.append(conf_matrix)\n",
    "\n",
    "    print(f\"Max Iterations: {max_iter}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display overall model performance\n",
    "best_max_iter = [100, 500, 1000][accuracy_list.index(max(accuracy_list))]\n",
    "print(f\"Best Max Iterations: {best_max_iter}\")\n",
    "print(\"Overall Model Performance:\")\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "print(f\"Overall Accuracy: {max(accuracy_list)}\")\n",
    "print(f\"Overall Confusion Matrix:\\n{conf_matrix_list[accuracy_list.index(max(accuracy_list))]}\")\n",
    "\n",
    "# Plot confusion matrix of the best performing model\n",
    "plt.figure()\n",
    "sns.heatmap(conf_matrix_list[accuracy_list.index(max(accuracy_list))], annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Best Performing Model)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
